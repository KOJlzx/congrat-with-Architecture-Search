{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b3c874e-9130-4c4a-b46a-bd5d4aa53a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch_geometric as pyg\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import clip_graph as cg\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a107a912-4c1c-4a3a-bced-1ab02b5cc48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/lizaixi/congrat-copy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5460a31-0d54-42ca-bd40-974165a25097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008d5219-357b-4f31-ac22-d509c7b257d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2969591811"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(2969591811)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7e81a-d6e6-48bc-818f-0cb7788b665f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What should we evaluate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595a559-d7f9-477d-b178-c9e822d90aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'pubmed': {\n",
    "        'svd_init_dataset': 'configs/eval-datasets/pubmed/gassocausal.yaml',\n",
    "        'svd_init_baseline': 'lightning_logs/gnn-pretrain/pubmed/version_138/',\n",
    "        'svd_init_key': 'x',\n",
    "        \n",
    "        'models': {\n",
    "            'causal': {\n",
    "                'base': 'lightning_logs/clip-graph/inductive-causal/pubmed/version_124/',\n",
    "                # 'sim10': 'lightning_logs/clip-graph/inductive-causal/pubmed/version_21/',\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e5f5d-bf47-4597-aee6-8eed13a5a14e",
   "metadata": {},
   "source": [
    "# Do the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63b92634-0832-49ce-889a-af91b5fa1b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(z, pos_edge_index, neg_edge_index=None, eps=1e-15):\n",
    "    if neg_edge_index is None:\n",
    "        neg_edge_index = pyg.utils.negative_sampling(pos_edge_index, z.size(0))\n",
    "    \n",
    "    pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "    neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "    y = torch.cat([pos_y, neg_y], dim=0).long()\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    decoder = pyg.nn.models.autoencoder.InnerProductDecoder()\n",
    "    pos_dec = decoder(z, pos_edge_index, sigmoid=True)\n",
    "    neg_dec = decoder(z, neg_edge_index, sigmoid=True)\n",
    "    pred = torch.cat([pos_dec, neg_dec], dim=0)\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    print('pred', pred)\n",
    "    return {\n",
    "        'auc': mt.roc_auc_score(y, pred),\n",
    "        'ap': mt.average_precision_score(y, pred),\n",
    "        \n",
    "        'recon': (\n",
    "            -torch.log(pos_dec + eps).mean() +\n",
    "            -torch.log(1 - neg_dec + eps).mean()\n",
    "        ).item(),\n",
    "        \n",
    "        # very good scores from our model, but poorly calibrated;\n",
    "        # let's just report the AUC/AP\n",
    "        # 'accuracy': mt.accuracy_score(y, pred > 0.5),\n",
    "        # 'precision': mt.precision_score(y, pred > 0.5),\n",
    "        # 'recall': mt.recall_score(y, pred > 0.5),\n",
    "        # 'f1': mt.f1_score(y, pred > 0.5),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d788ee30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b2a7bef17b485cbcfed273f4d0a088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neulab/anaconda3/envs/congrat/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_ids tensor([15502925,  8962136,  7548984,  ..., 12574327,  1535055, 10376780])\n",
      "in_split_compute_split_nodes\n",
      "in_split_splits\n",
      "{'train': tensor([15502925,  8962136,  7548984,  ..., 15924589,  9507963,  3513303]), 'val': tensor([18782902, 10406747,  9244304,  ..., 11049955, 15562143, 11194213]), 'test': tensor([16171015, 19587831, 17616607,  ..., 12574327,  1535055, 10376780])}\n",
      "in_split_splits_train_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n",
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_129/checkpoints/epoch=17-step=18.ckpt <class 'clip_graph.gassolit.LitGAE'>\n",
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_129/checkpoints/epoch=17-step=18.ckpt <class 'clip_graph.gassolit.LitGAE'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m## First, baselines\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     embs[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-baseline\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mgn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvei\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     42\u001b[39m     embs[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-untrained\u001b[39m\u001b[33m'\u001b[39m] = bl_model(vx, vei)[\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     45\u001b[39m res = pd.Series({\n\u001b[32m     46\u001b[39m     k : test(v, vei, vnei)\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tqdm(embs.items())\n\u001b[32m     48\u001b[39m }).apply(pd.Series)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/congrat/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/congrat/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lizaixi/congrat-copy/src/clip_graph/gassomodels.py:193\u001b[39m, in \u001b[36mGassoSpace.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight, is_search)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.step == \u001b[32m0\u001b[39m:\n\u001b[32m    192\u001b[39m     edge_index = edge_index.unsqueeze(\u001b[32m0\u001b[39m).repeat(\u001b[38;5;28mself\u001b[39m.num_layers, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     edge_weight = \u001b[43medge_weight\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m(\u001b[32m0\u001b[39m).repeat(\u001b[38;5;28mself\u001b[39m.num_layers, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m.adjs = (edge_index, edge_weight)\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m.step += \u001b[32m1\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for dataset, paths in tqdm(datasets.items()):\n",
    "    #\n",
    "    # Dataset and specific objects to input to models\n",
    "    #\n",
    "    \n",
    "    dm = cg.utils.datamodule_from_yaml(paths['svd_init_dataset'])['dm']\n",
    "\n",
    "    tx = getattr(dm.train_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    tei = dm.train_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    tnei = dm.train_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "\n",
    "    vx = getattr(dm.test_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    vei = dm.test_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    vnei = dm.test_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "\n",
    "    #\n",
    "    # Baselines\n",
    "    #\n",
    "    \n",
    "    ## Fine-tuned for graph autoencoding\n",
    "    gn_model = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)['model'].model.encoder\n",
    "    gn_model = gn_model.to(device)\n",
    "    \n",
    "    ## Same architecture, randomly initialized, totally untrained\n",
    "    ckpt = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)\n",
    "    cls = getattr(cg.models, ckpt['config']['model']['init_args']['model_class_name'])\n",
    "    params = ckpt['config']['model']['init_args']['model_params']\n",
    "    bl_model = cls(**params)\n",
    "    bl_model = bl_model.to(device)\n",
    "\n",
    "    #\n",
    "    # Generate embeddings\n",
    "    #\n",
    "\n",
    "    embs = {}\n",
    "\n",
    "    ## First, baselines\n",
    "    with torch.no_grad():\n",
    "        embs[f'{dataset}-baseline'] = gn_model(vx, vei)['output']\n",
    "        embs[f'{dataset}-untrained'] = bl_model(vx, vei)['output']\n",
    "        \n",
    "\n",
    "    res = pd.Series({\n",
    "        k : test(v, vei, vnei)\n",
    "        for k, v in tqdm(embs.items())\n",
    "    }).apply(pd.Series)\n",
    "    \n",
    "    res['dataset'] = res.index.str.split('-').map(lambda s: s[0])\n",
    "    res['model'] = res.index.str.split('-').map(lambda s: s[1])\n",
    "    res = res.reset_index(drop=True).set_index(['dataset', 'model'])\n",
    "    \n",
    "    results += [res]\n",
    "\n",
    "results = pd.concat(results, axis=0)\n",
    "results = results.sort_index()\n",
    "\n",
    "results.to_csv('data/link-prediction-eval.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6e2e01ce-807b-49b3-ad93-f3eab538ca1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b617b66a4c647f2aac52cbeefab49cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neulab/anaconda3/envs/congrat/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_ids tensor([15502925,  8962136,  7548984,  ..., 12574327,  1535055, 10376780])\n",
      "in_split_compute_split_nodes\n",
      "in_split_splits\n",
      "{'train': tensor([15502925,  8962136,  7548984,  ..., 15924589,  9507963,  3513303]), 'val': tensor([18782902, 10406747,  9244304,  ..., 11049955, 15562143, 11194213]), 'test': tensor([16171015, 19587831, 17616607,  ..., 12574327,  1535055, 10376780])}\n",
      "in_split_splits_train_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n",
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_135/checkpoints/epoch=16-step=17.ckpt <class 'clip_graph.gassolit.LitGAE'>\n",
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_135/checkpoints/epoch=16-step=17.ckpt <class 'clip_graph.gassolit.LitGAE'>\n",
      "1\n",
      "1\n",
      "****************************************************************************************************\n",
      "index tensor([0, 1, 2])\n",
      "selected_idx gat\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "selected_idx gcn\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "selected_idx gin\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "tensor([[ 0.0262,  0.0765, -0.0496,  ...,  0.0872,  0.0343,  0.0641],\n",
      "        [ 0.0092,  0.0258, -0.0223,  ...,  0.1032, -0.0359,  0.0349],\n",
      "        [-0.0018,  0.0230, -0.0224,  ...,  0.1053, -0.0335,  0.0278],\n",
      "        ...,\n",
      "        [ 0.0234,  0.0137, -0.0471,  ...,  0.1135, -0.0381,  0.0677],\n",
      "        [-0.0098,  0.0019, -0.0308,  ...,  0.0851, -0.0363,  0.0844],\n",
      "        [-0.0098,  0.0019, -0.0308,  ...,  0.0851, -0.0363,  0.0844]])\n",
      "tensor([[-0.0483, -0.1193, -0.1405,  ..., -0.6732,  0.6163, -0.0833],\n",
      "        [ 0.0884,  0.0527, -0.8174,  ...,  0.1512,  0.0351, -0.2926],\n",
      "        [-0.5050,  0.0531, -0.2843,  ..., -0.1532, -0.1471, -0.4483],\n",
      "        ...,\n",
      "        [ 0.1759,  0.2624, -0.1297,  ...,  0.1482,  0.6529,  0.1083],\n",
      "        [ 0.5932, -0.0719, -0.8044,  ..., -0.3335, -0.1682, -0.1588],\n",
      "        [ 0.0769, -0.6329, -0.5905,  ..., -0.5134,  0.0328, -0.7059]])\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3664dfc2b8414c7da4507df8de08312b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred [0.88528365 0.84901744 0.85401356 ... 0.8205377  0.82480156 0.81085163]\n",
      "pred [1.        1.        1.        ... 0.9999999 1.        1.       ]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for dataset, paths in tqdm(datasets.items()):\n",
    "    #\n",
    "    # Dataset and specific objects to input to models\n",
    "    #\n",
    "    \n",
    "    #clip_graph.data.datamodule.PubmedGraphTextDataModule\n",
    "    dm = cg.utils.datamodule_from_yaml(paths['svd_init_dataset'])['dm']\n",
    "    tx = getattr(dm.train_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    tw = dm.train_dataset.dataset.graph_data.edge_attr.to(device)\n",
    "    tei = dm.train_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    tnei = dm.train_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "    vx = getattr(dm.test_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    vw = dm.test_dataset.dataset.graph_data.edge_attr.to(device)\n",
    "    vei = dm.test_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    vnei = dm.test_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "\n",
    "    #\n",
    "    # Baselines\n",
    "    #\n",
    "    \n",
    "    ## Fine-tuned for graph autoencoding\n",
    "    gn_model = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)['model'].model.encoder\n",
    "    gn_model = gn_model.to(device)\n",
    "    \n",
    "    ## Same architecture, randomly initialized, totally untrained\n",
    "    ckpt = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)\n",
    "    import clip_graph.gassomodels as gm\n",
    "    cls = getattr(gm, ckpt['config']['model']['init_args']['model_class_name'])\n",
    "    params = ckpt['config']['model']['init_args']['model_params']\n",
    "    bl_model = cls(**params)\n",
    "    bl_model = bl_model.to(device)\n",
    "\n",
    "    #\n",
    "    # Generate embeddings\n",
    "    #\n",
    "\n",
    "    embs = {}\n",
    "\n",
    "    ## First, baselines\n",
    "    with torch.no_grad():\n",
    "        gn_model(vx, vei, vw)\n",
    "        bl_model(vx, vei, vw)\n",
    "        print(gn_model.step)\n",
    "        print(bl_model.step)\n",
    "        print(\"*\"*100)\n",
    "        embs[f'{dataset}-baseline'] = gn_model(vx, vei, vw, False)['output']\n",
    "        embs[f'{dataset}-untrained'] = bl_model(vx, vei, vw)['output']\n",
    "\n",
    "        # embs[f'{dataset}-baseline'] = gn_model(vx, vei)['output']\n",
    "        # embs[f'{dataset}-untrained'] = bl_model(vx, vei)['output']\n",
    "    print(embs[f'{dataset}-baseline'])\n",
    "    print(embs[f'{dataset}-untrained'])\n",
    "    print(\"*\"*100)\n",
    "    ## Other models\n",
    "    # for lmtype in tqdm(paths['models'].keys()):\n",
    "    #     for mod, path in tqdm(paths['models'][lmtype].items()):\n",
    "    #         # print(\"--_____________________\")\n",
    "    #         # print(path, dm)\n",
    "    #         #lightning_logs/clip-graph/inductive-causal/pubmed/version_21/ \n",
    "    #         # {Train dataloader: size=511}\n",
    "    #         # {Validation dataloader: size=32}\n",
    "    #         # {Test dataloader: size=84}\n",
    "    #         # {Predict dataloader: None}\n",
    "    #         cg_model = cg.scoring.interpret_ckpt_dir(path, dm)['model'].model\n",
    "    #         cg_model = cg_model.to(device)\n",
    "    #         cg_model.embed_nodes(vx, vei, vw)\n",
    "    #         embs[f'{dataset}-{lmtype}_{mod}'] = F.normalize(cg_model.embed_nodes(vx, vei, vw), p=2, dim=1)\n",
    "    \n",
    "\n",
    "    # for epoch in range(5):\n",
    "    #     embs = gn_model(vx, vei, vw, False)['output']\n",
    "\n",
    "    res = pd.Series({\n",
    "        k : test(v, vei, vnei)\n",
    "        for k, v in tqdm(embs.items())\n",
    "    }).apply(pd.Series)\n",
    "    \n",
    "    res['dataset'] = res.index.str.split('-').map(lambda s: s[0])\n",
    "    res['model'] = res.index.str.split('-').map(lambda s: s[1])\n",
    "    res = res.reset_index(drop=True).set_index(['dataset', 'model'])\n",
    "    \n",
    "    results += [res]\n",
    "\n",
    "results = pd.concat(results, axis=0)\n",
    "results = results.sort_index()\n",
    "\n",
    "results.to_csv('data/link-prediction-eval.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0bed4-83e1-4fe5-bade-59747459f5c8",
   "metadata": {},
   "source": [
    "# Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c6f13a3-5b2b-480e-aa79-78079f3797f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('data/link-prediction-eval.csv')\n",
    "results = results.set_index(['dataset', 'model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd492f43-cc18-4494-b811-26070b273589",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4ed0071-da8a-4529-8995-f1989e8c80e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>ap</th>\n",
       "      <th>recon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pubmed</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.928630</td>\n",
       "      <td>0.909511</td>\n",
       "      <td>1.920344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>untrained</th>\n",
       "      <td>0.527625</td>\n",
       "      <td>0.514205</td>\n",
       "      <td>33.288082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        auc        ap      recon\n",
       "dataset model                                   \n",
       "pubmed  baseline   0.928630  0.909511   1.920344\n",
       "        untrained  0.527625  0.514205  33.288082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e2dd7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b85d282-be37-45c2-acdb-82cb0a2733f5",
   "metadata": {},
   "source": [
    "## Tables for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67bb12-41f4-4af3-b2eb-84842a71e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/4258940796.py:74: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  tmp = tmp.drop('alpha', axis=1)\n"
     ]
    }
   ],
   "source": [
    "mods = [\n",
    "    'baseline', 'untrained',\n",
    "    'causal_base', \n",
    "]\n",
    "\n",
    "tmp = results.loc[pd.IndexSlice[:, mods], :].sort_index()\n",
    "tmp = tmp['auc'].reset_index().copy()\n",
    "\n",
    "model_map = {\n",
    "    **{\n",
    "        k : k\n",
    "        for k in tmp['model'].unique()\n",
    "        if k not in ('baseline', 'untrained')\n",
    "    },\n",
    "    \n",
    "    **{\n",
    "        'baseline': 'baseline_svd',\n",
    "        'untrained': 'baseline_untrained',\n",
    "    }\n",
    "}\n",
    "\n",
    "tmp['model'] = tmp['model'].map(model_map)\n",
    "tmp['type'] = tmp['model'].apply(lambda s: s.split('_')[0])\n",
    "tmp['model'] = tmp['model'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "tmp = tmp.loc[tmp['model'] != 'untrained', :]\n",
    "\n",
    "tmp = tmp.set_index(['dataset', 'type', 'model'])\n",
    "tmp = tmp.sort_index()\n",
    "tmp = tmp.unstack(0)\n",
    "tmp.columns = tmp.columns.droplevel(0)\n",
    "tmp = tmp.loc[['causal', 'baseline'], :]\n",
    "\n",
    "tmp.index = tmp.index.set_levels(tmp.index.levels[0].map({\n",
    "    'causal': 'Causal',\n",
    "    'baseline': 'GNN Autoencoder',\n",
    "}), level=0)\n",
    "\n",
    "tmp.index = tmp.index.set_levels(tmp.index.levels[1].map({\n",
    "    'base': r'$\\alpha = 0$',\n",
    "    'sim10': r'$\\alpha = 0.1$',\n",
    "    'svd': 'SVD',\n",
    "    'untrained': 'Untrained GNN',\n",
    "}), level=1)\n",
    "\n",
    "tmp.index.names = ['', '']\n",
    "tmp.index = tmp.index.swaplevel()\n",
    "tmp = tmp.sort_index()\n",
    "\n",
    "tmp = tmp[['pubmed']]\n",
    "\n",
    "tmp.columns = tmp.columns.map({\n",
    "    'pubmed': 'Undirected-Pubmed',\n",
    "    'trex': 'Undirected-TRex',\n",
    "    'twitter_small': 'Undirected-Twitter',\n",
    "\n",
    "    'pubmed_directed': 'Directed-Pubmed',\n",
    "    'trex_directed': 'Directed-TRex',\n",
    "    'twitter_small_directed': 'Directed-Twitter'\n",
    "})\n",
    "\n",
    "tmp.columns = pd.MultiIndex.from_frame(pd.DataFrame(tmp.columns.to_series().reset_index(drop=True).str.split('-').tolist()))\n",
    "\n",
    "tmp.columns.name = ''\n",
    "tmp.columns.names = ['', '']\n",
    "\n",
    "tmp.index.names = ['alpha', 'txt']\n",
    "tmp = tmp.reset_index()\n",
    "tmp['txt'] = 'ConGraT-' + tmp['txt']\n",
    "tmp['txt'] = tmp['txt'] + ' (' + tmp['alpha'] + ')'\n",
    "\n",
    "tmp.loc[tmp['txt'] == 'ConGraT-GNN Autoencoder (Baseline)', 'txt'] = 'GAT Autoencoder (Baseline)'\n",
    "\n",
    "tmp = tmp.drop('alpha', axis=1)\n",
    "\n",
    "# tmp = tmp.apply(np.roll, shift=1)\n",
    "\n",
    "tmp = tmp.set_index('txt')\n",
    "tmp.index.name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec6f481-b351-46aa-b00b-c495d933b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/2449844411.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ut.bold_above_thresh(s[:-1], s[-2]),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5d12a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" ></th>\n",
       "      <th id=\"T_5d12a_level0_col0\" class=\"col_heading level0 col0\" >Undirected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" ></th>\n",
       "      <th id=\"T_5d12a_level1_col0\" class=\"col_heading level1 col0\" >Pubmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" ></th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5d12a_level0_row0\" class=\"row_heading level0 row0\" >ConGraT-Causal ($\\alpha = 0$)</th>\n",
       "      <td id=\"T_5d12a_row0_col0\" class=\"data row0 col0\" >0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d12a_level0_row1\" class=\"row_heading level0 row1\" >ConGraT-GNN Autoencoder (SVD)</th>\n",
       "      <td id=\"T_5d12a_row1_col0\" class=\"data row1 col0\" >0.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff12f897dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bold_except_last_row(s):\n",
    "    return pd.concat([\n",
    "        ut.bold_above_thresh(s[:-1], s[-2]),\n",
    "        pd.Series([''], index=[s.index[-1]]),\n",
    "    ])\n",
    "\n",
    "tab = tmp.style \\\n",
    "    .format(precision=3, na_rep='--') \\\n",
    "    .apply(bold_except_last_row, axis=0)\n",
    "    \n",
    "with pd.option_context('display.html.use_mathjax', True):\n",
    "    display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632fc88-a556-4696-a288-7b1039aae9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[ht]\n",
      "\\centering\n",
      "\\label{tab:link-prediction}\n",
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      " & Undirected \\\\\n",
      " & Pubmed \\\\\n",
      " &  \\\\\n",
      "\\midrule\n",
      "ConGraT-Causal ($\\alpha = 0$) & 0.962 \\\\\n",
      "ConGraT-GNN Autoencoder (SVD) & 0.760 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/2449844411.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ut.bold_above_thresh(s[:-1], s[-2]),\n"
     ]
    }
   ],
   "source": [
    "print(tab.to_latex(\n",
    "        hrules = True,\n",
    "        column_format = 'lcccccc',\n",
    "        position = 'ht',\n",
    "        label = 'tab:link-prediction',\n",
    "        multicol_align = '|c',\n",
    "        position_float = 'centering',\n",
    "        environment = 'table*',\n",
    "        convert_css = True,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf490bc-9363-4fe0-8b1d-f293366264c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "congrat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
