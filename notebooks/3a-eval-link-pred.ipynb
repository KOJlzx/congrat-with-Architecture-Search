{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b3c874e-9130-4c4a-b46a-bd5d4aa53a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch_geometric as pyg\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import clip_graph as cg\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a107a912-4c1c-4a3a-bced-1ab02b5cc48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/lizaixi/congrat-copy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5460a31-0d54-42ca-bd40-974165a25097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "008d5219-357b-4f31-ac22-d509c7b257d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2969591811"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(2969591811)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7e81a-d6e6-48bc-818f-0cb7788b665f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What should we evaluate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595a559-d7f9-477d-b178-c9e822d90aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'pubmed': {\n",
    "        'svd_init_dataset': 'configs/eval-datasets/pubmed/gassocausal.yaml',\n",
    "        'svd_init_baseline': 'lightning_logs/gnn-pretrain/pubmed/version_2/',\n",
    "        'svd_init_key': 'x',\n",
    "        \n",
    "        'models': {\n",
    "            'causal': {\n",
    "                'base': 'lightning_logs/clip-graph/inductive-causal/pubmed/version_102/',\n",
    "                # 'sim10': 'lightning_logs/clip-graph/inductive-causal/pubmed/version_21/',\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e5f5d-bf47-4597-aee6-8eed13a5a14e",
   "metadata": {},
   "source": [
    "# Do the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63b92634-0832-49ce-889a-af91b5fa1b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(z, pos_edge_index, neg_edge_index=None, eps=1e-15):\n",
    "    if neg_edge_index is None:\n",
    "        neg_edge_index = pyg.utils.negative_sampling(pos_edge_index, z.size(0))\n",
    "    \n",
    "    pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "    neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "    y = torch.cat([pos_y, neg_y], dim=0).long()\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    decoder = pyg.nn.models.autoencoder.InnerProductDecoder()\n",
    "    pos_dec = decoder(z, pos_edge_index, sigmoid=True)\n",
    "    neg_dec = decoder(z, neg_edge_index, sigmoid=True)\n",
    "    pred = torch.cat([pos_dec, neg_dec], dim=0)\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    return {\n",
    "        'auc': mt.roc_auc_score(y, pred),\n",
    "        'ap': mt.average_precision_score(y, pred),\n",
    "        \n",
    "        'recon': (\n",
    "            -torch.log(pos_dec + eps).mean() +\n",
    "            -torch.log(1 - neg_dec + eps).mean()\n",
    "        ).item(),\n",
    "        \n",
    "        # very good scores from our model, but poorly calibrated;\n",
    "        # let's just report the AUC/AP\n",
    "        # 'accuracy': mt.accuracy_score(y, pred > 0.5),\n",
    "        # 'precision': mt.precision_score(y, pred > 0.5),\n",
    "        # 'recall': mt.recall_score(y, pred > 0.5),\n",
    "        # 'f1': mt.f1_score(y, pred > 0.5),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e2e01ce-807b-49b3-ad93-f3eab538ca1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ae95d26e0b4d2e97c38da27bd64fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 72\n",
      "in_get_graph_object\n",
      "in_get_graph_object_pickle_load\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neulab/anaconda3/envs/congrat/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_graph_text_dataset_init_super\n",
      "in_graph_dataset_mixin_init\n",
      "in_text_dataset_init\n",
      "in_text_dataset_init_super\n",
      "in_text_dataset_init_tokenizer\n",
      "in_text_dataset_init_tokenizer_pad_token\n",
      "in_text_dataset_init_tokenizer_params\n",
      "in_graph_dataset_mixin_init_super\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "torch.Size([2, 122178])\n",
      "torch.Size([122178, 1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "in_graph_dataset_mixin_init_graph_data\n",
      "new_edge_attr torch.Size([122178, 1])\n",
      "pre_edge_attr torch.Size([122178, 1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "in_graph_dataset_mixin_init_drop_isolates\n",
      "in_graph_text_dataset_init\n",
      "in_graph_text_dataset_init_unique_text_node_ids\n",
      "in_setup_graph_text_dataset_extract_subgraph_with_texts\n",
      "node_mask tensor([True, True, True,  ..., True, True, True]) --------------------------------------------------\n",
      "node_idx tensor([    0,     1,     2,  ..., 19713, 19714, 19715]) --------------------------------------------------\n",
      "self.graph_data.edge_index's shape torch.Size([2, 122178]) --------------------------------------------------\n",
      "k_hop 1 --------------------------------------------------\n",
      "self.graph_data.node_ids tensor([ 2502462,  6368290,  2962892,  ..., 10857959,  9231661,  3275556]) --------------------------------------------------\n",
      "subset tensor([    0,     1,     2,  ..., 19713, 19714, 19715]) --------------------------------------------------\n",
      "subset's shape torch.Size([19716]) --------------------------------------------------\n",
      "new_node_ids tensor([ 2502462,  6368290,  2962892,  ..., 10857959,  9231661,  3275556]) --------------------------------------------------\n",
      "text_mask tensor([True, True, True,  ..., True, True, True]) --------------------------------------------------\n",
      "in_setup_graph_text_dataset\n",
      "in_split_compute_split_nodes\n",
      "in_split_splits\n",
      "{'train': tensor([15502925,  8962136,  7548984,  ..., 15924589,  9507963,  3513303]), 'val': tensor([18782902, 10406747,  9244304,  ..., 11049955, 15562143, 11194213]), 'test': tensor([16171015, 19587831, 17616607,  ..., 12574327,  1535055, 10376780])}\n",
      "new_edge_attr torch.Size([59643, 1])\n",
      "pre_edge_attr torch.Size([122178, 1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "new_edge_attr torch.Size([1302, 1])\n",
      "pre_edge_attr torch.Size([122178, 1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "new_edge_attr torch.Size([4905, 1])\n",
      "pre_edge_attr torch.Size([122178, 1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "new_edge_attr torch.Size([59643, 1])\n",
      "pre_edge_attr torch.Size([59643, 1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "new_edge_attr torch.Size([1302, 1])\n",
      "pre_edge_attr torch.Size([1302, 1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "new_edge_attr torch.Size([4905, 1])\n",
      "pre_edge_attr torch.Size([4905, 1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "in_split_splits_train_dataset\n",
      "in_setup_graph_text_dataset_split\n",
      "in_graph_dataset_mixin_compute_mutuals\n",
      "in_graph_dataset_mixin_compute_mutuals_A_to_device\n",
      "torch.cuda.is_available(): True\n",
      "torch.Size([12212, 12212]) --------------------------------------------------\n",
      "in_graph_dataset_mixin_compute_mutuals_with_torch_no_grad\n",
      "in_graph_dataset_mixin_compute_mutuals_F_normalize\n",
      "in_graph_dataset_mixin_compute_mutuals_mutual_T\n",
      "in_graph_dataset_mixin_compute_mutuals_mutual_cpu\n",
      "in_setup_graph_text_dataset_compute_mutuals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_graph_dataset_mixin_compute_mutuals\n",
      "in_graph_dataset_mixin_compute_mutuals_A_to_device\n",
      "torch.cuda.is_available(): True\n",
      "torch.Size([713, 713]) --------------------------------------------------\n",
      "in_graph_dataset_mixin_compute_mutuals_with_torch_no_grad\n",
      "in_graph_dataset_mixin_compute_mutuals_F_normalize\n",
      "in_graph_dataset_mixin_compute_mutuals_mutual_T\n",
      "in_graph_dataset_mixin_compute_mutuals_mutual_cpu\n",
      "in_setup_graph_text_dataset_compute_mutuals\n",
      "in_graph_dataset_mixin_compute_mutuals\n",
      "in_graph_dataset_mixin_compute_mutuals_A_to_device\n",
      "torch.cuda.is_available(): True\n",
      "torch.Size([1996, 1996]) --------------------------------------------------\n",
      "in_graph_dataset_mixin_compute_mutuals_with_torch_no_grad\n",
      "in_graph_dataset_mixin_compute_mutuals_F_normalize\n",
      "in_graph_dataset_mixin_compute_mutuals_mutual_T\n",
      "in_graph_dataset_mixin_compute_mutuals_mutual_cpu\n",
      "in_setup_graph_text_dataset_compute_mutuals\n",
      "tensor([[-0.2111,  0.8552, -0.3588,  ...,  0.1306, -1.5901, -0.3376],\n",
      "        [-0.2444, -0.1007, -0.0971,  ..., -0.4502, -1.1200, -0.4807],\n",
      "        [-0.2474, -0.2113, -0.0678,  ...,  0.3517, -0.2644, -0.9737],\n",
      "        ...,\n",
      "        [-0.2470, -0.2319, -0.0432,  ..., -0.1171,  0.1650,  0.1707],\n",
      "        [-0.1866, -0.2519, -0.0171,  ..., -0.7523, -0.2500,  0.4303],\n",
      "        [-0.2467, -0.2161, -0.0644,  ..., -1.0549,  0.2058, -0.4937]]) tensor([[    0,     0,     0,  ..., 12209, 12210, 12211],\n",
      "        [    1,     2,     3,  ..., 11644,  1791,  5787]]) tensor([[ 2095, 11070,  6579,  ..., 11732,  8572,  7385],\n",
      "        [ 6081,  2358,  3360,  ...,  6098,   524,  5774]])\n",
      "yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_2/checkpoints/epoch=19-step=20.ckpt <class 'clip_graph.lit.LitGAE'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_2/checkpoints/epoch=19-step=20.ckpt <class 'clip_graph.lit.LitGAE'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caec00488a624f51a513eaed1cd6a36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbc89273d8b432fbd80f8ee9a2cfa39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++ lightning_logs/clip-graph/inductive-causal/pubmed/version_102/checkpoints/epoch=3-step=36748.ckpt <class 'clip_graph.gassolit.LitClipGraph'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++ lightning_logs/clip-graph/inductive-causal/pubmed/version_21/checkpoints/epoch=7-step=73496.ckpt <class 'clip_graph.lit.LitClipGraph'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ClipGraph.embed_nodes() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m         cg_model = cg.scoring.interpret_ckpt_dir(path, dm)[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m].model\n\u001b[32m     59\u001b[39m         cg_model = cg_model.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         \u001b[43mcg_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m         embs[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlmtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = F.normalize(cg_model.embed_nodes(vx, vei, vw), p=\u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     63\u001b[39m res = pd.Series({\n\u001b[32m     64\u001b[39m     k : test(v, vei, vnei)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tqdm(embs.items())\n\u001b[32m     66\u001b[39m }).apply(pd.Series)\n",
      "\u001b[31mTypeError\u001b[39m: ClipGraph.embed_nodes() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for dataset, paths in tqdm(datasets.items()):\n",
    "    #\n",
    "    # Dataset and specific objects to input to models\n",
    "    #\n",
    "    \n",
    "    #clip_graph.data.datamodule.PubmedGraphTextDataModule\n",
    "    dm = cg.utils.datamodule_from_yaml(paths['svd_init_dataset'])['dm']\n",
    "\n",
    "    tx = getattr(dm.train_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    tw = dm.train_dataset.dataset.graph_data.edge_attr.to(device)\n",
    "    tei = dm.train_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    tnei = dm.train_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "    print(tx, tei, tnei)\n",
    "    print('y'*100)\n",
    "    vx = getattr(dm.test_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    vw = dm.test_dataset.dataset.graph_data.edge_attr.to(device)\n",
    "    vei = dm.test_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    vnei = dm.test_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "\n",
    "    #\n",
    "    # Baselines\n",
    "    #\n",
    "    \n",
    "    ## Fine-tuned for graph autoencoding\n",
    "    gn_model = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)['model'].model.encoder\n",
    "    gn_model = gn_model.to(device)\n",
    "    \n",
    "    ## Same architecture, randomly initialized, totally untrained\n",
    "    ckpt = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)\n",
    "    cls = getattr(cg.models, ckpt['config']['model']['init_args']['model_class_name'])\n",
    "    params = ckpt['config']['model']['init_args']['model_params']\n",
    "    bl_model = cls(**params)\n",
    "    bl_model = bl_model.to(device)\n",
    "\n",
    "    #\n",
    "    # Generate embeddings\n",
    "    #\n",
    "\n",
    "    embs = {}\n",
    "\n",
    "    ## First, baselines\n",
    "    with torch.no_grad():\n",
    "        embs[f'{dataset}-baseline'] = gn_model(vx, vei)['output']\n",
    "        embs[f'{dataset}-untrained'] = bl_model(vx, vei)['output']\n",
    "        \n",
    "    ## Other models\n",
    "    for lmtype in tqdm(paths['models'].keys()):\n",
    "        for mod, path in tqdm(paths['models'][lmtype].items()):\n",
    "            # print(\"--_____________________\")\n",
    "            # print(path, dm)\n",
    "            #lightning_logs/clip-graph/inductive-causal/pubmed/version_21/ \n",
    "            # {Train dataloader: size=511}\n",
    "            # {Validation dataloader: size=32}\n",
    "            # {Test dataloader: size=84}\n",
    "            # {Predict dataloader: None}\n",
    "            cg_model = cg.scoring.interpret_ckpt_dir(path, dm)['model'].model\n",
    "            cg_model = cg_model.to(device)\n",
    "            cg_model.embed_nodes(vx, vei, vw)\n",
    "            embs[f'{dataset}-{lmtype}_{mod}'] = F.normalize(cg_model.embed_nodes(vx, vei, vw), p=2, dim=1)\n",
    "    \n",
    "    res = pd.Series({\n",
    "        k : test(v, vei, vnei)\n",
    "        for k, v in tqdm(embs.items())\n",
    "    }).apply(pd.Series)\n",
    "    \n",
    "    res['dataset'] = res.index.str.split('-').map(lambda s: s[0])\n",
    "    res['model'] = res.index.str.split('-').map(lambda s: s[1])\n",
    "    res = res.reset_index(drop=True).set_index(['dataset', 'model'])\n",
    "    \n",
    "    results += [res]\n",
    "\n",
    "results = pd.concat(results, axis=0)\n",
    "results = results.sort_index()\n",
    "\n",
    "results.to_csv('data/link-prediction-eval.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0bed4-83e1-4fe5-bade-59747459f5c8",
   "metadata": {},
   "source": [
    "# Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6f13a3-5b2b-480e-aa79-78079f3797f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('data/link-prediction-eval.csv')\n",
    "results = results.set_index(['dataset', 'model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd492f43-cc18-4494-b811-26070b273589",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ed0071-da8a-4529-8995-f1989e8c80e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>ap</th>\n",
       "      <th>recon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">pubmed</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.759655</td>\n",
       "      <td>0.800513</td>\n",
       "      <td>1.767621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>causal_base</th>\n",
       "      <td>0.962295</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>1.271247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>causal_sim10</th>\n",
       "      <td>0.962773</td>\n",
       "      <td>0.954242</td>\n",
       "      <td>1.274712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>untrained</th>\n",
       "      <td>0.536332</td>\n",
       "      <td>0.520224</td>\n",
       "      <td>29.225744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           auc        ap      recon\n",
       "dataset model                                      \n",
       "pubmed  baseline      0.759655  0.800513   1.767621\n",
       "        causal_base   0.962295  0.953642   1.271247\n",
       "        causal_sim10  0.962773  0.954242   1.274712\n",
       "        untrained     0.536332  0.520224  29.225744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85d282-be37-45c2-acdb-82cb0a2733f5",
   "metadata": {},
   "source": [
    "## Tables for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b67bb12-41f4-4af3-b2eb-84842a71e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/4258940796.py:74: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  tmp = tmp.drop('alpha', axis=1)\n"
     ]
    }
   ],
   "source": [
    "mods = [\n",
    "    'baseline', 'untrained',\n",
    "    'causal_base', \n",
    "]\n",
    "\n",
    "tmp = results.loc[pd.IndexSlice[:, mods], :].sort_index()\n",
    "tmp = tmp['auc'].reset_index().copy()\n",
    "\n",
    "model_map = {\n",
    "    **{\n",
    "        k : k\n",
    "        for k in tmp['model'].unique()\n",
    "        if k not in ('baseline', 'untrained')\n",
    "    },\n",
    "    \n",
    "    **{\n",
    "        'baseline': 'baseline_svd',\n",
    "        'untrained': 'baseline_untrained',\n",
    "    }\n",
    "}\n",
    "\n",
    "tmp['model'] = tmp['model'].map(model_map)\n",
    "tmp['type'] = tmp['model'].apply(lambda s: s.split('_')[0])\n",
    "tmp['model'] = tmp['model'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "tmp = tmp.loc[tmp['model'] != 'untrained', :]\n",
    "\n",
    "tmp = tmp.set_index(['dataset', 'type', 'model'])\n",
    "tmp = tmp.sort_index()\n",
    "tmp = tmp.unstack(0)\n",
    "tmp.columns = tmp.columns.droplevel(0)\n",
    "tmp = tmp.loc[['causal', 'baseline'], :]\n",
    "\n",
    "tmp.index = tmp.index.set_levels(tmp.index.levels[0].map({\n",
    "    'causal': 'Causal',\n",
    "    'baseline': 'GNN Autoencoder',\n",
    "}), level=0)\n",
    "\n",
    "tmp.index = tmp.index.set_levels(tmp.index.levels[1].map({\n",
    "    'base': r'$\\alpha = 0$',\n",
    "    'sim10': r'$\\alpha = 0.1$',\n",
    "    'svd': 'SVD',\n",
    "    'untrained': 'Untrained GNN',\n",
    "}), level=1)\n",
    "\n",
    "tmp.index.names = ['', '']\n",
    "tmp.index = tmp.index.swaplevel()\n",
    "tmp = tmp.sort_index()\n",
    "\n",
    "tmp = tmp[['pubmed']]\n",
    "\n",
    "tmp.columns = tmp.columns.map({\n",
    "    'pubmed': 'Undirected-Pubmed',\n",
    "    'trex': 'Undirected-TRex',\n",
    "    'twitter_small': 'Undirected-Twitter',\n",
    "\n",
    "    'pubmed_directed': 'Directed-Pubmed',\n",
    "    'trex_directed': 'Directed-TRex',\n",
    "    'twitter_small_directed': 'Directed-Twitter'\n",
    "})\n",
    "\n",
    "tmp.columns = pd.MultiIndex.from_frame(pd.DataFrame(tmp.columns.to_series().reset_index(drop=True).str.split('-').tolist()))\n",
    "\n",
    "tmp.columns.name = ''\n",
    "tmp.columns.names = ['', '']\n",
    "\n",
    "tmp.index.names = ['alpha', 'txt']\n",
    "tmp = tmp.reset_index()\n",
    "tmp['txt'] = 'ConGraT-' + tmp['txt']\n",
    "tmp['txt'] = tmp['txt'] + ' (' + tmp['alpha'] + ')'\n",
    "\n",
    "tmp.loc[tmp['txt'] == 'ConGraT-GNN Autoencoder (Baseline)', 'txt'] = 'GAT Autoencoder (Baseline)'\n",
    "\n",
    "tmp = tmp.drop('alpha', axis=1)\n",
    "\n",
    "# tmp = tmp.apply(np.roll, shift=1)\n",
    "\n",
    "tmp = tmp.set_index('txt')\n",
    "tmp.index.name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ec6f481-b351-46aa-b00b-c495d933b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/2449844411.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ut.bold_above_thresh(s[:-1], s[-2]),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5d12a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" ></th>\n",
       "      <th id=\"T_5d12a_level0_col0\" class=\"col_heading level0 col0\" >Undirected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" ></th>\n",
       "      <th id=\"T_5d12a_level1_col0\" class=\"col_heading level1 col0\" >Pubmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" ></th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5d12a_level0_row0\" class=\"row_heading level0 row0\" >ConGraT-Causal ($\\alpha = 0$)</th>\n",
       "      <td id=\"T_5d12a_row0_col0\" class=\"data row0 col0\" >0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d12a_level0_row1\" class=\"row_heading level0 row1\" >ConGraT-GNN Autoencoder (SVD)</th>\n",
       "      <td id=\"T_5d12a_row1_col0\" class=\"data row1 col0\" >0.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff12f897dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bold_except_last_row(s):\n",
    "    return pd.concat([\n",
    "        ut.bold_above_thresh(s[:-1], s[-2]),\n",
    "        pd.Series([''], index=[s.index[-1]]),\n",
    "    ])\n",
    "\n",
    "tab = tmp.style \\\n",
    "    .format(precision=3, na_rep='--') \\\n",
    "    .apply(bold_except_last_row, axis=0)\n",
    "    \n",
    "with pd.option_context('display.html.use_mathjax', True):\n",
    "    display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f632fc88-a556-4696-a288-7b1039aae9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[ht]\n",
      "\\centering\n",
      "\\label{tab:link-prediction}\n",
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      " & Undirected \\\\\n",
      " & Pubmed \\\\\n",
      " &  \\\\\n",
      "\\midrule\n",
      "ConGraT-Causal ($\\alpha = 0$) & 0.962 \\\\\n",
      "ConGraT-GNN Autoencoder (SVD) & 0.760 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/2449844411.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ut.bold_above_thresh(s[:-1], s[-2]),\n"
     ]
    }
   ],
   "source": [
    "print(tab.to_latex(\n",
    "        hrules = True,\n",
    "        column_format = 'lcccccc',\n",
    "        position = 'ht',\n",
    "        label = 'tab:link-prediction',\n",
    "        multicol_align = '|c',\n",
    "        position_float = 'centering',\n",
    "        environment = 'table*',\n",
    "        convert_css = True,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf490bc-9363-4fe0-8b1d-f293366264c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "congrat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
