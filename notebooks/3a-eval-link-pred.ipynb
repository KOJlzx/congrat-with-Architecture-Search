{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3c874e-9130-4c4a-b46a-bd5d4aa53a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch_geometric as pyg\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import clip_graph as cg\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a107a912-4c1c-4a3a-bced-1ab02b5cc48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser('~/lizaixi/congrat-copy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5460a31-0d54-42ca-bd40-974165a25097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008d5219-357b-4f31-ac22-d509c7b257d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2969591811"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(2969591811)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7e81a-d6e6-48bc-818f-0cb7788b665f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What should we evaluate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3595a559-d7f9-477d-b178-c9e822d90aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'pubmed': {\n",
    "        'svd_init_dataset': 'configs/eval-datasets/pubmed/gassocausal.yaml',\n",
    "        'svd_init_baseline': 'lightning_logs/gnn-pretrain/pubmed/version_35/',\n",
    "        'svd_init_key': 'x',\n",
    "        \n",
    "        'models': {\n",
    "            'causal': {\n",
    "                'base': 'lightning_logs/clip-graph/inductive-causal/pubmed/version_104/',\n",
    "                # 'sim10': 'lightning_logs/clip-graph/inductive-causal/pubmed/version_21/',\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e5f5d-bf47-4597-aee6-8eed13a5a14e",
   "metadata": {},
   "source": [
    "# Do the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b92634-0832-49ce-889a-af91b5fa1b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(z, pos_edge_index, neg_edge_index=None, eps=1e-15):\n",
    "    if neg_edge_index is None:\n",
    "        neg_edge_index = pyg.utils.negative_sampling(pos_edge_index, z.size(0))\n",
    "    \n",
    "    pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "    neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "    y = torch.cat([pos_y, neg_y], dim=0).long()\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    decoder = pyg.nn.models.autoencoder.InnerProductDecoder()\n",
    "    pos_dec = decoder(z, pos_edge_index, sigmoid=True)\n",
    "    neg_dec = decoder(z, neg_edge_index, sigmoid=True)\n",
    "    pred = torch.cat([pos_dec, neg_dec], dim=0)\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    print('pred', pred)\n",
    "    return {\n",
    "        'auc': mt.roc_auc_score(y, pred),\n",
    "        'ap': mt.average_precision_score(y, pred),\n",
    "        \n",
    "        'recon': (\n",
    "            -torch.log(pos_dec + eps).mean() +\n",
    "            -torch.log(1 - neg_dec + eps).mean()\n",
    "        ).item(),\n",
    "        \n",
    "        # very good scores from our model, but poorly calibrated;\n",
    "        # let's just report the AUC/AP\n",
    "        # 'accuracy': mt.accuracy_score(y, pred > 0.5),\n",
    "        # 'precision': mt.precision_score(y, pred > 0.5),\n",
    "        # 'recall': mt.recall_score(y, pred > 0.5),\n",
    "        # 'f1': mt.f1_score(y, pred > 0.5),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d788ee30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb94afac7abc4f739373483811a08e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neulab/anaconda3/envs/congrat/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_graph_text_dataset_init_super\n",
      "in_graph_dataset_mixin_init\n",
      "in_text_dataset_init\n",
      "in_text_dataset_init_super\n",
      "in_text_dataset_init_tokenizer\n",
      "in_text_dataset_init_tokenizer_pad_token\n",
      "in_text_dataset_init_tokenizer_params\n",
      "in_graph_dataset_mixin_init_super\n",
      "in_graph_text_dataset_init\n",
      "in_graph_text_dataset_init_unique_text_node_ids\n",
      "node_mask tensor([True, True, True,  ..., True, True, True]) --------------------------------------------------\n",
      "node_idx tensor([    0,     1,     2,  ..., 19713, 19714, 19715]) --------------------------------------------------\n",
      "self.graph_data.edge_index's shape torch.Size([2, 122178]) --------------------------------------------------\n",
      "k_hop 1 --------------------------------------------------\n",
      "in_split_compute_split_nodes\n",
      "in_split_splits\n",
      "{'train': tensor([15502925,  8962136,  7548984,  ..., 15924589,  9507963,  3513303]), 'val': tensor([18782902, 10406747,  9244304,  ..., 11049955, 15562143, 11194213]), 'test': tensor([16171015, 19587831, 17616607,  ..., 12574327,  1535055, 10376780])}\n",
      "in_split_splits_train_dataset\n",
      "torch.Size([12212, 12212]) --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([713, 713]) --------------------------------------------------\n",
      "torch.Size([1996, 1996]) --------------------------------------------------\n",
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_20/checkpoints/epoch=19-step=20.ckpt <class 'clip_graph.lit.LitGAE'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_20/checkpoints/epoch=19-step=20.ckpt <class 'clip_graph.lit.LitGAE'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a2d307881341288b127f335f92e012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred [0.04217182 0.8476207  0.27928746 ... 0.7291003  0.05302127 0.5017917 ]\n",
      "pred [0.9999752  0.99999905 1.         ... 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for dataset, paths in tqdm(datasets.items()):\n",
    "    #\n",
    "    # Dataset and specific objects to input to models\n",
    "    #\n",
    "    \n",
    "    dm = cg.utils.datamodule_from_yaml(paths['svd_init_dataset'])['dm']\n",
    "\n",
    "    tx = getattr(dm.train_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    tei = dm.train_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    tnei = dm.train_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "\n",
    "    vx = getattr(dm.test_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    vei = dm.test_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    vnei = dm.test_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "\n",
    "    #\n",
    "    # Baselines\n",
    "    #\n",
    "    \n",
    "    ## Fine-tuned for graph autoencoding\n",
    "    gn_model = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)['model'].model.encoder\n",
    "    gn_model = gn_model.to(device)\n",
    "    \n",
    "    ## Same architecture, randomly initialized, totally untrained\n",
    "    ckpt = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)\n",
    "    cls = getattr(cg.models, ckpt['config']['model']['init_args']['model_class_name'])\n",
    "    params = ckpt['config']['model']['init_args']['model_params']\n",
    "    bl_model = cls(**params)\n",
    "    bl_model = bl_model.to(device)\n",
    "\n",
    "    #\n",
    "    # Generate embeddings\n",
    "    #\n",
    "\n",
    "    embs = {}\n",
    "\n",
    "    ## First, baselines\n",
    "    with torch.no_grad():\n",
    "        embs[f'{dataset}-baseline'] = gn_model(vx, vei)['output']\n",
    "        embs[f'{dataset}-untrained'] = bl_model(vx, vei)['output']\n",
    "        \n",
    "\n",
    "    res = pd.Series({\n",
    "        k : test(v, vei, vnei)\n",
    "        for k, v in tqdm(embs.items())\n",
    "    }).apply(pd.Series)\n",
    "    \n",
    "    res['dataset'] = res.index.str.split('-').map(lambda s: s[0])\n",
    "    res['model'] = res.index.str.split('-').map(lambda s: s[1])\n",
    "    res = res.reset_index(drop=True).set_index(['dataset', 'model'])\n",
    "    \n",
    "    results += [res]\n",
    "\n",
    "results = pd.concat(results, axis=0)\n",
    "results = results.sort_index()\n",
    "\n",
    "results.to_csv('data/link-prediction-eval.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e2e01ce-807b-49b3-ad93-f3eab538ca1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f897d472534011b0402df37227b866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neulab/anaconda3/envs/congrat/lib/python3.11/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_graph_text_dataset_init_super\n",
      "in_graph_dataset_mixin_init\n",
      "in_text_dataset_init\n",
      "in_text_dataset_init_super\n",
      "in_text_dataset_init_tokenizer\n",
      "in_text_dataset_init_tokenizer_pad_token\n",
      "in_text_dataset_init_tokenizer_params\n",
      "in_graph_dataset_mixin_init_super\n",
      "in_graph_text_dataset_init\n",
      "in_graph_text_dataset_init_unique_text_node_ids\n",
      "node_mask tensor([True, True, True,  ..., True, True, True]) --------------------------------------------------\n",
      "node_idx tensor([    0,     1,     2,  ..., 19713, 19714, 19715]) --------------------------------------------------\n",
      "self.graph_data.edge_index's shape torch.Size([2, 122178]) --------------------------------------------------\n",
      "k_hop 1 --------------------------------------------------\n",
      "in_split_compute_split_nodes\n",
      "in_split_splits\n",
      "{'train': tensor([15502925,  8962136,  7548984,  ..., 15924589,  9507963,  3513303]), 'val': tensor([18782902, 10406747,  9244304,  ..., 11049955, 15562143, 11194213]), 'test': tensor([16171015, 19587831, 17616607,  ..., 12574327,  1535055, 10376780])}\n",
      "in_split_splits_train_dataset\n",
      "torch.Size([12212, 12212]) --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2969591811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([713, 713]) --------------------------------------------------\n",
      "torch.Size([1996, 1996]) --------------------------------------------------\n",
      "++++++++++++++++++++ lightning_logs/gnn-pretrain/pubmed/version_35/checkpoints/epoch=20-step=21.ckpt <class 'clip_graph.gassolit.LitGAE'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LitGAE:\n\tUnexpected key(s) in state_dict: \"model.encoder.alphas_normal.0\", \"model.encoder.alphas_normal.1\", \"model.encoder.alphas_normal.2\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     17\u001b[39m vnei = dm.test_dataset.dataset.graph_data.neg_edge_index.to(device)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Baselines\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m## Fine-tuned for graph autoencoding\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m gn_model = \u001b[43mcg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterpret_ckpt_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msvd_init_baseline\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m].model.encoder\n\u001b[32m     25\u001b[39m gn_model = gn_model.to(device)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m## Same architecture, randomly initialized, totally untrained\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lizaixi/congrat-copy/src/clip_graph/scoring.py:66\u001b[39m, in \u001b[36minterpret_ckpt_dir\u001b[39m\u001b[34m(ckpt_dir, dm, device)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(checkpoint):  \u001b[38;5;66;03m# is normal PL checkpoint\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m++++++++++++++++++++\u001b[39m\u001b[33m\"\u001b[39m, checkpoint, kls)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     model = \u001b[43mkls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# is deepspeed checkpoint\u001b[39;00m\n\u001b[32m     68\u001b[39m     sd_path = os.path.join(checkpoint, \u001b[33m'\u001b[39m\u001b[33mstate_dict.pt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/congrat/lib/python3.11/site-packages/pytorch_lightning/utilities/model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/congrat/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1611\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[32m   1523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n\u001b[32m   1524\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1529\u001b[39m     **kwargs: Any,\n\u001b[32m   1530\u001b[39m ) -> Self:\n\u001b[32m   1531\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[32m   1532\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[32m   1533\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1609\u001b[39m \n\u001b[32m   1610\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1611\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1612\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1619\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/congrat/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:91\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, **kwargs)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl.LightningModule):\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     model = \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     state_dict = checkpoint[\u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/congrat/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:187\u001b[39m, in \u001b[36m_load_state\u001b[39m\u001b[34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[39m\n\u001b[32m    184\u001b[39m     obj.on_load_checkpoint(checkpoint)\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m keys = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate_dict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m keys.missing_keys:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/congrat/lib/python3.11/site-packages/torch/nn/modules/module.py:2215\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2210\u001b[39m         error_msgs.insert(\n\u001b[32m   2211\u001b[39m             \u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m'\u001b[39m.format(\n\u001b[32m   2212\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[32m   2214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   2216\u001b[39m                        \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)))\n\u001b[32m   2217\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for LitGAE:\n\tUnexpected key(s) in state_dict: \"model.encoder.alphas_normal.0\", \"model.encoder.alphas_normal.1\", \"model.encoder.alphas_normal.2\". "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for dataset, paths in tqdm(datasets.items()):\n",
    "    #\n",
    "    # Dataset and specific objects to input to models\n",
    "    #\n",
    "    \n",
    "    #clip_graph.data.datamodule.PubmedGraphTextDataModule\n",
    "    dm = cg.utils.datamodule_from_yaml(paths['svd_init_dataset'])['dm']\n",
    "    tx = getattr(dm.train_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    tw = dm.train_dataset.dataset.graph_data.edge_attr.to(device)\n",
    "    tei = dm.train_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    tnei = dm.train_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "    vx = getattr(dm.test_dataset.dataset.graph_data, paths['svd_init_key']).to(device)\n",
    "    vw = dm.test_dataset.dataset.graph_data.edge_attr.to(device)\n",
    "    vei = dm.test_dataset.dataset.graph_data.edge_index.to(device)\n",
    "    vnei = dm.test_dataset.dataset.graph_data.neg_edge_index.to(device)\n",
    "\n",
    "    #\n",
    "    # Baselines\n",
    "    #\n",
    "    \n",
    "    ## Fine-tuned for graph autoencoding\n",
    "    gn_model = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)['model'].model.encoder\n",
    "    gn_model = gn_model.to(device)\n",
    "    \n",
    "    ## Same architecture, randomly initialized, totally untrained\n",
    "    ckpt = cg.scoring.interpret_ckpt_dir(paths['svd_init_baseline'], dm)\n",
    "    import clip_graph.gassomodels as gm\n",
    "    cls = getattr(gm, ckpt['config']['model']['init_args']['model_class_name'])\n",
    "    params = ckpt['config']['model']['init_args']['model_params']\n",
    "    bl_model = cls(**params)\n",
    "    bl_model = bl_model.to(device)\n",
    "\n",
    "    #\n",
    "    # Generate embeddings\n",
    "    #\n",
    "\n",
    "    embs = {}\n",
    "\n",
    "    ## First, baselines\n",
    "    with torch.no_grad():\n",
    "        gn_model(vx, vei, vw)\n",
    "        bl_model(vx, vei, vw)\n",
    "        print(gn_model.step)\n",
    "        print(bl_model.step)\n",
    "        print(\"*\"*100)\n",
    "        embs[f'{dataset}-baseline'] = gn_model(vx, vei, vw)['output']\n",
    "        embs[f'{dataset}-untrained'] = bl_model(vx, vei, vw)['output']\n",
    "\n",
    "        # embs[f'{dataset}-baseline'] = gn_model(vx, vei)['output']\n",
    "        # embs[f'{dataset}-untrained'] = bl_model(vx, vei)['output']\n",
    "    print(embs[f'{dataset}-baseline'])\n",
    "    print(embs[f'{dataset}-untrained'])\n",
    "    print(\"*\"*100)\n",
    "    ## Other models\n",
    "    # for lmtype in tqdm(paths['models'].keys()):\n",
    "    #     for mod, path in tqdm(paths['models'][lmtype].items()):\n",
    "    #         # print(\"--_____________________\")\n",
    "    #         # print(path, dm)\n",
    "    #         #lightning_logs/clip-graph/inductive-causal/pubmed/version_21/ \n",
    "    #         # {Train dataloader: size=511}\n",
    "    #         # {Validation dataloader: size=32}\n",
    "    #         # {Test dataloader: size=84}\n",
    "    #         # {Predict dataloader: None}\n",
    "    #         cg_model = cg.scoring.interpret_ckpt_dir(path, dm)['model'].model\n",
    "    #         cg_model = cg_model.to(device)\n",
    "    #         cg_model.embed_nodes(vx, vei, vw)\n",
    "    #         embs[f'{dataset}-{lmtype}_{mod}'] = F.normalize(cg_model.embed_nodes(vx, vei, vw), p=2, dim=1)\n",
    "    \n",
    "    for k, v in embs.items():\n",
    "        print(k, v)\n",
    "    res = pd.Series({\n",
    "        k : test(v, vei, vnei)\n",
    "        for k, v in tqdm(embs.items())\n",
    "    }).apply(pd.Series)\n",
    "    \n",
    "    res['dataset'] = res.index.str.split('-').map(lambda s: s[0])\n",
    "    res['model'] = res.index.str.split('-').map(lambda s: s[1])\n",
    "    res = res.reset_index(drop=True).set_index(['dataset', 'model'])\n",
    "    \n",
    "    results += [res]\n",
    "\n",
    "results = pd.concat(results, axis=0)\n",
    "results = results.sort_index()\n",
    "\n",
    "results.to_csv('data/link-prediction-eval.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0bed4-83e1-4fe5-bade-59747459f5c8",
   "metadata": {},
   "source": [
    "# Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c6f13a3-5b2b-480e-aa79-78079f3797f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('data/link-prediction-eval.csv')\n",
    "results = results.set_index(['dataset', 'model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd492f43-cc18-4494-b811-26070b273589",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4ed0071-da8a-4529-8995-f1989e8c80e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>ap</th>\n",
       "      <th>recon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pubmed</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.755377</td>\n",
       "      <td>0.775429</td>\n",
       "      <td>1.653534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>untrained</th>\n",
       "      <td>0.527625</td>\n",
       "      <td>0.514205</td>\n",
       "      <td>33.288082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        auc        ap      recon\n",
       "dataset model                                   \n",
       "pubmed  baseline   0.755377  0.775429   1.653534\n",
       "        untrained  0.527625  0.514205  33.288082"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e2dd7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b85d282-be37-45c2-acdb-82cb0a2733f5",
   "metadata": {},
   "source": [
    "## Tables for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b67bb12-41f4-4af3-b2eb-84842a71e18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/4258940796.py:74: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  tmp = tmp.drop('alpha', axis=1)\n"
     ]
    }
   ],
   "source": [
    "mods = [\n",
    "    'baseline', 'untrained',\n",
    "    'causal_base', \n",
    "]\n",
    "\n",
    "tmp = results.loc[pd.IndexSlice[:, mods], :].sort_index()\n",
    "tmp = tmp['auc'].reset_index().copy()\n",
    "\n",
    "model_map = {\n",
    "    **{\n",
    "        k : k\n",
    "        for k in tmp['model'].unique()\n",
    "        if k not in ('baseline', 'untrained')\n",
    "    },\n",
    "    \n",
    "    **{\n",
    "        'baseline': 'baseline_svd',\n",
    "        'untrained': 'baseline_untrained',\n",
    "    }\n",
    "}\n",
    "\n",
    "tmp['model'] = tmp['model'].map(model_map)\n",
    "tmp['type'] = tmp['model'].apply(lambda s: s.split('_')[0])\n",
    "tmp['model'] = tmp['model'].apply(lambda s: s.split('_')[1])\n",
    "\n",
    "tmp = tmp.loc[tmp['model'] != 'untrained', :]\n",
    "\n",
    "tmp = tmp.set_index(['dataset', 'type', 'model'])\n",
    "tmp = tmp.sort_index()\n",
    "tmp = tmp.unstack(0)\n",
    "tmp.columns = tmp.columns.droplevel(0)\n",
    "tmp = tmp.loc[['causal', 'baseline'], :]\n",
    "\n",
    "tmp.index = tmp.index.set_levels(tmp.index.levels[0].map({\n",
    "    'causal': 'Causal',\n",
    "    'baseline': 'GNN Autoencoder',\n",
    "}), level=0)\n",
    "\n",
    "tmp.index = tmp.index.set_levels(tmp.index.levels[1].map({\n",
    "    'base': r'$\\alpha = 0$',\n",
    "    'sim10': r'$\\alpha = 0.1$',\n",
    "    'svd': 'SVD',\n",
    "    'untrained': 'Untrained GNN',\n",
    "}), level=1)\n",
    "\n",
    "tmp.index.names = ['', '']\n",
    "tmp.index = tmp.index.swaplevel()\n",
    "tmp = tmp.sort_index()\n",
    "\n",
    "tmp = tmp[['pubmed']]\n",
    "\n",
    "tmp.columns = tmp.columns.map({\n",
    "    'pubmed': 'Undirected-Pubmed',\n",
    "    'trex': 'Undirected-TRex',\n",
    "    'twitter_small': 'Undirected-Twitter',\n",
    "\n",
    "    'pubmed_directed': 'Directed-Pubmed',\n",
    "    'trex_directed': 'Directed-TRex',\n",
    "    'twitter_small_directed': 'Directed-Twitter'\n",
    "})\n",
    "\n",
    "tmp.columns = pd.MultiIndex.from_frame(pd.DataFrame(tmp.columns.to_series().reset_index(drop=True).str.split('-').tolist()))\n",
    "\n",
    "tmp.columns.name = ''\n",
    "tmp.columns.names = ['', '']\n",
    "\n",
    "tmp.index.names = ['alpha', 'txt']\n",
    "tmp = tmp.reset_index()\n",
    "tmp['txt'] = 'ConGraT-' + tmp['txt']\n",
    "tmp['txt'] = tmp['txt'] + ' (' + tmp['alpha'] + ')'\n",
    "\n",
    "tmp.loc[tmp['txt'] == 'ConGraT-GNN Autoencoder (Baseline)', 'txt'] = 'GAT Autoencoder (Baseline)'\n",
    "\n",
    "tmp = tmp.drop('alpha', axis=1)\n",
    "\n",
    "# tmp = tmp.apply(np.roll, shift=1)\n",
    "\n",
    "tmp = tmp.set_index('txt')\n",
    "tmp.index.name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ec6f481-b351-46aa-b00b-c495d933b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/2449844411.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ut.bold_above_thresh(s[:-1], s[-2]),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5d12a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" ></th>\n",
       "      <th id=\"T_5d12a_level0_col0\" class=\"col_heading level0 col0\" >Undirected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level1\" ></th>\n",
       "      <th id=\"T_5d12a_level1_col0\" class=\"col_heading level1 col0\" >Pubmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" ></th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5d12a_level0_row0\" class=\"row_heading level0 row0\" >ConGraT-Causal ($\\alpha = 0$)</th>\n",
       "      <td id=\"T_5d12a_row0_col0\" class=\"data row0 col0\" >0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d12a_level0_row1\" class=\"row_heading level0 row1\" >ConGraT-GNN Autoencoder (SVD)</th>\n",
       "      <td id=\"T_5d12a_row1_col0\" class=\"data row1 col0\" >0.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff12f897dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bold_except_last_row(s):\n",
    "    return pd.concat([\n",
    "        ut.bold_above_thresh(s[:-1], s[-2]),\n",
    "        pd.Series([''], index=[s.index[-1]]),\n",
    "    ])\n",
    "\n",
    "tab = tmp.style \\\n",
    "    .format(precision=3, na_rep='--') \\\n",
    "    .apply(bold_except_last_row, axis=0)\n",
    "    \n",
    "with pd.option_context('display.html.use_mathjax', True):\n",
    "    display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f632fc88-a556-4696-a288-7b1039aae9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[ht]\n",
      "\\centering\n",
      "\\label{tab:link-prediction}\n",
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      " & Undirected \\\\\n",
      " & Pubmed \\\\\n",
      " &  \\\\\n",
      "\\midrule\n",
      "ConGraT-Causal ($\\alpha = 0$) & 0.962 \\\\\n",
      "ConGraT-GNN Autoencoder (SVD) & 0.760 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875611/2449844411.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ut.bold_above_thresh(s[:-1], s[-2]),\n"
     ]
    }
   ],
   "source": [
    "print(tab.to_latex(\n",
    "        hrules = True,\n",
    "        column_format = 'lcccccc',\n",
    "        position = 'ht',\n",
    "        label = 'tab:link-prediction',\n",
    "        multicol_align = '|c',\n",
    "        position_float = 'centering',\n",
    "        environment = 'table*',\n",
    "        convert_css = True,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf490bc-9363-4fe0-8b1d-f293366264c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "congrat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
